{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61JnOTXwTtxF",
        "outputId": "dc5e3ca2-ca7e-4bed-d10d-88ff24f0ca98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report, f1_score\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Conv3D, MaxPooling3D, Flatten, Dense, Dropout, GlobalAveragePooling3D\n",
        "import cv2\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "base_dir = '/content/drive/MyDrive/cricshot'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4PiJuiecVEk",
        "outputId": "7ee3c788-fe42-43c9-c023-91e46d87603d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.16.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.3.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.31.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.17,>=2.16 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.16.2)\n",
            "Requirement already satisfied: keras>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow) (13.7.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow) (0.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.6.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->tensorflow) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_frames(video_path, num_frames=16, img_size=(224, 224)):\n",
        "    frames = []\n",
        "    try:\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "        if total_frames < num_frames:\n",
        "            indices = np.linspace(0, total_frames - 1, total_frames, dtype=int)\n",
        "        else:\n",
        "            indices = np.linspace(0, total_frames - 1, num_frames, dtype=int)\n",
        "        for i in indices:\n",
        "            cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
        "            ret, frame = cap.read()\n",
        "            if ret:\n",
        "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "                frame = cv2.resize(frame, img_size)\n",
        "                frames.append(frame)\n",
        "        cap.release()\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing video: {video_path}\")\n",
        "        print(f\"Error message: {str(e)}\")\n",
        "\n",
        "    if len(frames) == 0:\n",
        "        print(f\"No frames extracted from video: {video_path}\")\n",
        "        return None\n",
        "\n",
        "    while len(frames) < num_frames:\n",
        "        frames.append(frames[-1])\n",
        "\n",
        "    return np.array(frames) / 255.0"
      ],
      "metadata": {
        "id": "CA0i6ja3T8ts"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_dataframes(base_dir, num_frames=16):\n",
        "    filepaths = []\n",
        "    labels = []\n",
        "    classlist = sorted(os.listdir(base_dir))\n",
        "\n",
        "    if not classlist:\n",
        "        raise ValueError(f\"No subdirectories found in {base_dir}. Please check the path.\")\n",
        "\n",
        "    for klass in classlist:\n",
        "        classpath = os.path.join(base_dir, klass)\n",
        "        if os.path.isdir(classpath):\n",
        "            flist = sorted([f for f in os.listdir(classpath) if f.lower().endswith(('.mp4', '.avi', '.mov'))])\n",
        "            if not flist:\n",
        "                print(f\"Warning: No video files found in {classpath}\")\n",
        "                continue\n",
        "            desc = f'{klass:25s}'\n",
        "            for f in tqdm(flist, ncols=130, desc=desc, unit='files', colour='blue'):\n",
        "                fpath = os.path.join(classpath, f)\n",
        "                filepaths.append(fpath)\n",
        "                labels.append(klass)\n",
        "\n",
        "    if not filepaths:\n",
        "        raise ValueError(f\"No video files found in any subdirectory of {base_dir}. Please check the content of the directories.\")\n",
        "\n",
        "    df = pd.DataFrame({'filepaths': filepaths, 'labels': labels})\n",
        "    train_df, temp_df = train_test_split(df, train_size=0.7, stratify=df['labels'], random_state=42)\n",
        "    valid_df, test_df = train_test_split(temp_df, train_size=0.5, stratify=temp_df['labels'], random_state=42)\n",
        "\n",
        "    print('train_df length:', len(train_df), '  valid_df length:', len(valid_df), '  test_df length:', len(test_df))\n",
        "    return train_df, valid_df, test_df\n",
        "try:\n",
        "    train_df, valid_df, test_df = make_dataframes(base_dir)\n",
        "except ValueError as e:\n",
        "    print(f\"Error: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vP7K2mivURFj",
        "outputId": "562c73ec-9fc9-4031-b680-5a42eccd4789"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "cover                    : 100%|\u001b[34m██████████████████████████████████████████████████████████\u001b[0m| 188/188 [00:00<00:00, 31546.21files/s]\u001b[0m\n",
            "defense                  : 100%|\u001b[34m█████████████████████████████████████████████████████████\u001b[0m| 192/192 [00:00<00:00, 210537.61files/s]\u001b[0m\n",
            "flick                    : 100%|\u001b[34m█████████████████████████████████████████████████████████\u001b[0m| 181/181 [00:00<00:00, 270648.49files/s]\u001b[0m\n",
            "hook                     : 100%|\u001b[34m█████████████████████████████████████████████████████████\u001b[0m| 181/181 [00:00<00:00, 272592.11files/s]\u001b[0m\n",
            "late_cut                 : 100%|\u001b[34m█████████████████████████████████████████████████████████\u001b[0m| 182/182 [00:00<00:00, 284943.38files/s]\u001b[0m\n",
            "lofted                   : 100%|\u001b[34m█████████████████████████████████████████████████████████\u001b[0m| 198/198 [00:00<00:00, 295331.50files/s]\u001b[0m\n",
            "pull                     : 100%|\u001b[34m█████████████████████████████████████████████████████████\u001b[0m| 179/179 [00:00<00:00, 290437.30files/s]\u001b[0m\n",
            "square_cut               : 100%|\u001b[34m█████████████████████████████████████████████████████████\u001b[0m| 200/200 [00:00<00:00, 296836.80files/s]\u001b[0m\n",
            "straight                 : 100%|\u001b[34m█████████████████████████████████████████████████████████\u001b[0m| 193/193 [00:00<00:00, 302843.50files/s]\u001b[0m\n",
            "sweep                    : 100%|\u001b[34m█████████████████████████████████████████████████████████\u001b[0m| 194/194 [00:00<00:00, 291438.03files/s]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_df length: 1321   valid_df length: 283   test_df length: 284\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class VideoDataGenerator(keras.utils.Sequence):\n",
        "    def __init__(self, dataframe, batch_size, num_frames, num_classes, img_size=(224, 224), shuffle=True):\n",
        "        self.df = dataframe\n",
        "        self.batch_size = batch_size\n",
        "        self.num_frames = num_frames\n",
        "        self.num_classes = num_classes\n",
        "        self.img_size = img_size\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.df) / float(self.batch_size)))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_df = self.df.iloc[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "\n",
        "        batch_videos = []\n",
        "        batch_labels = []\n",
        "\n",
        "        for _, row in batch_df.iterrows():\n",
        "            video = extract_frames(row['filepaths'], self.num_frames, self.img_size)\n",
        "            if video is not None:\n",
        "                batch_videos.append(video)\n",
        "                label = keras.utils.to_categorical(row['label_index'], num_classes=self.num_classes)\n",
        "                batch_labels.append(label)\n",
        "\n",
        "        if not batch_videos:\n",
        "            return self.__getitem__((idx + 1) % len(self))\n",
        "        return np.array(batch_videos), np.array(batch_labels)\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            self.df = self.df.sample(frac=1).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "QJalmk93UVPK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = sorted(train_df['labels'].unique())\n",
        "class_to_index = {cls: idx for idx, cls in enumerate(classes)}\n",
        "\n",
        "for df in [train_df, valid_df, test_df]:\n",
        "    df['label_index'] = df['labels'].map(class_to_index)\n",
        "\n",
        "num_classes = len(classes)\n",
        "batch_size = 16\n",
        "num_frames = 15\n",
        "img_size = (224, 224)\n",
        "\n",
        "train_gen = VideoDataGenerator(train_df, batch_size, num_frames, num_classes, img_size=img_size)\n",
        "valid_gen = VideoDataGenerator(valid_df, batch_size, num_frames, num_classes, img_size=img_size, shuffle=False)"
      ],
      "metadata": {
        "id": "d1N7zLsDUZL0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_model(num_frames, img_size, num_classes, lr=0.001):\n",
        "    input_shape = (num_frames, *img_size, 3)\n",
        "    model = keras.Sequential([\n",
        "        keras.layers.Conv3D(32, (3, 3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
        "        keras.layers.MaxPooling3D((1, 2, 2)),\n",
        "        keras.layers.Conv3D(64, (3, 3, 3), activation='relu', padding='same'),\n",
        "        keras.layers.MaxPooling3D((1, 2, 2)),\n",
        "        keras.layers.Conv3D(128, (3, 3, 3), activation='relu', padding='same'),\n",
        "        keras.layers.MaxPooling3D((1, 2, 2)),\n",
        "        keras.layers.Conv3D(256, (3, 3, 3), activation='relu', padding='same'),\n",
        "        keras.layers.GlobalAveragePooling3D(),\n",
        "        keras.layers.Dense(512, activation='relu'),\n",
        "        keras.layers.Dropout(0.5),\n",
        "        keras.layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(learning_rate=lr), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "num_frames = 15\n",
        "num_classes = len(train_df['labels'].unique())\n",
        "img_size = (224, 224)\n",
        "\n",
        "print(f\"Number of frames: {num_frames}\")\n",
        "print(f\"Image size: {img_size}\")\n",
        "print(f\"Number of classes: {num_classes}\")\n",
        "\n",
        "batch_size = 16\n",
        "train_gen = VideoDataGenerator(train_df, batch_size, num_frames, num_classes, img_size=img_size)\n",
        "valid_gen = VideoDataGenerator(valid_df, batch_size, num_frames, num_classes, img_size=img_size, shuffle=False)\n",
        "model = make_model(num_frames, (224, 224), num_classes)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 596
        },
        "id": "nCJQsRnMV_aA",
        "outputId": "9aaeac7b-0ca5-475f-b9e3-610d9a1948c5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of frames: 15\n",
            "Image size: (224, 224)\n",
            "Number of classes: 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv3d (\u001b[38;5;33mConv3D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │           \u001b[38;5;34m2,624\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling3d (\u001b[38;5;33mMaxPooling3D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv3d_1 (\u001b[38;5;33mConv3D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m55,360\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling3d_1 (\u001b[38;5;33mMaxPooling3D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv3d_2 (\u001b[38;5;33mConv3D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │         \u001b[38;5;34m221,312\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling3d_2 (\u001b[38;5;33mMaxPooling3D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv3d_3 (\u001b[38;5;33mConv3D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)     │         \u001b[38;5;34m884,992\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling3d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling3D\u001b[0m)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │         \u001b[38;5;34m131,584\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m5,130\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv3d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv3D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,624</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling3d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling3D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv3d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv3D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">55,360</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling3d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling3D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv3d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv3D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">221,312</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling3d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling3D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv3d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv3D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">884,992</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling3d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling3D</span>)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">5,130</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,301,002\u001b[0m (4.96 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,301,002</span> (4.96 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,301,002\u001b[0m (4.96 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,301,002</span> (4.96 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6)\n",
        "epochs = 20\n",
        "callbacks = [early_stop, reduce_lr]\n",
        "\n",
        "history = model.fit(\n",
        "    train_gen,\n",
        "    epochs=epochs,\n",
        "    verbose=1,\n",
        "    callbacks=callbacks,\n",
        "    validation_data=valid_gen,\n",
        "    validation_steps=None,\n",
        "    shuffle=False,\n",
        "    initial_epoch=0\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1b6u9h0WByD",
        "outputId": "c3a98afb-0cf6-48e1-c762-e47a686574be"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m44/83\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:38:01\u001b[0m 151s/step - accuracy: 0.1175 - loss: 2.3039"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tr_plot(tr_data, start_epoch):\n",
        "    tacc = tr_data.history['accuracy']\n",
        "    tloss = tr_data.history['loss']\n",
        "    vacc = tr_data.history['val_accuracy']\n",
        "    vloss = tr_data.history['val_loss']\n",
        "    Epoch_count = len(tacc) + start_epoch\n",
        "    Epochs = [i for i in range(start_epoch, Epoch_count)]\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n",
        "    ax1.plot(Epochs, tloss, 'r', label='Training loss')\n",
        "    ax1.plot(Epochs, vloss, 'g', label='Validation loss')\n",
        "    ax1.set_title('Training and Validation Loss')\n",
        "    ax1.set_xlabel('Epochs')\n",
        "    ax1.set_ylabel('Loss')\n",
        "    ax1.legend()\n",
        "    ax2.plot(Epochs, tacc, 'r', label='Training Accuracy')\n",
        "    ax2.plot(Epochs, vacc, 'g', label='Validation Accuracy')\n",
        "    ax2.set_title('Training and Validation Accuracy')\n",
        "    ax2.set_xlabel('Epochs')\n",
        "    ax2.set_ylabel('Accuracy')\n",
        "    ax2.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "tr_plot(history, 0)"
      ],
      "metadata": {
        "id": "lJOZI2cgWEPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predictor(test_gen):\n",
        "    y_pred = []\n",
        "    y_true = test_gen.df['label_index'].values\n",
        "    classes = list(test_gen.df['labels'].unique())\n",
        "    class_count = len(classes)\n",
        "    errors = 0\n",
        "    preds = model.predict(test_gen, verbose=1)\n",
        "    tests = len(preds)\n",
        "    for i, p in enumerate(preds):\n",
        "        pred_index = np.argmax(p)\n",
        "        true_index = test_gen.df['label_index'].iloc[i]\n",
        "        if pred_index != true_index:\n",
        "            errors += 1\n",
        "        y_pred.append(pred_index)\n",
        "\n",
        "    acc = (1 - errors / tests) * 100\n",
        "    print(f'There were {errors} errors in {tests} tests for an accuracy of {acc:.2f}%')\n",
        "    y_pred = np.array(y_pred)\n",
        "    y_true = np.array(y_true)\n",
        "    f1score = f1_score(y_true, y_pred, average='weighted') * 100\n",
        "    if class_count <= 30:\n",
        "        cm = confusion_matrix(y_true, y_pred)\n",
        "        plt.figure(figsize=(12, 8))\n",
        "        sns.heatmap(cm, annot=True, vmin=0, fmt='g', cmap='Blues', cbar=False)\n",
        "        plt.xticks(np.arange(class_count) + .5, classes, rotation=90)\n",
        "        plt.yticks(np.arange(class_count) + .5, classes, rotation=0)\n",
        "        plt.xlabel(\"Predicted\")\n",
        "        plt.ylabel(\"Actual\")\n",
        "        plt.title(\"Confusion Matrix\")\n",
        "        plt.show()\n",
        "\n",
        "    clr = classification_report(y_true, y_pred, target_names=classes, digits=4)\n",
        "    print(\"Classification Report:\\n----------------------\\n\", clr)\n",
        "    return errors, tests, f1score\n",
        "\n",
        "errors, tests, f1score = predictor(test_gen)"
      ],
      "metadata": {
        "id": "0a1ftYoKWKCH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "name = f'CRICKET-{len(train_gen.df[\"labels\"].unique())}-({224}x{224})'\n",
        "save_id = f'{name}-{f1score:.2f}.h5'\n",
        "model_save_loc = os.path.join('/content/drive/MyDrive', save_id)\n",
        "model.save(model_save_loc)\n",
        "print(f'Model was saved as {model_save_loc}')"
      ],
      "metadata": {
        "id": "PTxZYgGBWNHP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}